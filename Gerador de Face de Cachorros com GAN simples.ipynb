{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gjTm28G2tC6"
      },
      "source": [
        "## GAN simples para criação de faces de cachorros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY6UksTg2y2D"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H06EKcnhxLcM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from zipfile import ZipFile\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RmpKRoe3LDw"
      },
      "source": [
        "## Funções Uteis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91DeiLbpxv5_"
      },
      "outputs": [],
      "source": [
        "def plot_multiple_images_tf(X_train, ammount_images, n_cols=None):\n",
        "\n",
        "    random_indices = np.random.choice(X_train.shape[0], ammount_images, replace=False)\n",
        "\n",
        "    random_indices = tf.convert_to_tensor(random_indices, dtype=tf.int32)\n",
        "\n",
        "    images = tf.gather(X_train, random_indices)\n",
        "\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "\n",
        "    plt.figure(figsize=(n_cols * 3, n_rows * 3))\n",
        "\n",
        "    for index, image_tensor in enumerate(images):\n",
        "        image = image_tensor.numpy()\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images(target_size=(128, 128)):\n",
        "\n",
        "    train_dir = '/content/dogs/data/train/dogs'\n",
        "\n",
        "    X_train = []\n",
        "\n",
        "    for image_name in os.listdir(train_dir):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, target_size)\n",
        "\n",
        "        img = img.astype(np.float32) / 255\n",
        "        X_train.append(img)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    X_train = tf.stack(X_train)\n",
        "    return X_train\n",
        "\n",
        "\n",
        "# Load and preprocess images\n",
        "X_train = load_and_preprocess_images()\n"
      ],
      "metadata": {
        "id": "M_-ZDnk0Uedw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "id": "3wLt3Z5IUzxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_multiple_images_tf(X_train,16, n_cols=4)"
      ],
      "metadata": {
        "id": "_BryWlTYU0sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK_wgrR0xAan"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1vx-poh9BZp"
      },
      "source": [
        "### Gerador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxnRLKojwkmG"
      },
      "outputs": [],
      "source": [
        "random_normal_dimensions = 256\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(64, activation=\"selu\", input_shape=[random_normal_dimensions]),\n",
        "    keras.layers.Dense(128, activation=\"selu\"),\n",
        "    keras.layers.Dense(256, activation=\"selu\"),\n",
        "    keras.layers.Dense(512, activation=\"selu\"),\n",
        "    keras.layers.Dense(128 * 128 * 3, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([128, 128,3])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xs3vARf08Vx"
      },
      "source": [
        "### Passando barulho para gerador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjk8x15gz_S2"
      },
      "outputs": [],
      "source": [
        "test_noise = tf.random.normal([16, random_normal_dimensions])\n",
        "\n",
        "test_image = generator(test_noise)\n",
        "\n",
        "plot_multiple_images_tf(test_image, 16, n_cols=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMxfJA7R_7ls"
      },
      "source": [
        "### Discriminador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIn8IBVp9StA"
      },
      "outputs": [],
      "source": [
        "discriminator = keras.models.Sequential([\n",
        "    keras.Input(shape=(128, 128,3)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(512, activation=\"selu\"),\n",
        "    keras.layers.Dense(256, activation=\"selu\"),\n",
        "    keras.layers.Dense(128, activation=\"selu\"),\n",
        "    keras.layers.Dense(64, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6HnpPN59Te2"
      },
      "outputs": [],
      "source": [
        "gan = keras.models.Sequential([generator, discriminator])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lKpOq-Cw-r5"
      },
      "outputs": [],
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVsJ5-VY3oCg"
      },
      "source": [
        "## Treinando o modelo\n",
        "\n",
        "\n",
        "* Fase 1 - treina o discriminador com dados reais e falsos\n",
        "* Fase 2 - treina o gerador\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRt1ocLO2lx1"
      },
      "outputs": [],
      "source": [
        "def train_gan(gan, dataset, random_normal_dimensions, n_epochs=50):\n",
        "\n",
        "\n",
        "    generator, discriminator = gan.layers\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Época {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for real_images in dataset:\n",
        "            batch_size = real_images.shape[0]\n",
        "\n",
        "            # Fase 1\n",
        "            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n",
        "\n",
        "            fake_images = generator(noise)\n",
        "\n",
        "            mixed_images = tf.concat([fake_images, real_images], axis=0)\n",
        "\n",
        "            discriminator_labels = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "\n",
        "            discriminator.trainable = True\n",
        "\n",
        "            discriminator.train_on_batch(mixed_images, discriminator_labels)\n",
        "\n",
        "            # Fase 2\n",
        "            noise = tf.random.normal(shape=[batch_size, random_normal_dimensions])\n",
        "\n",
        "            generator_labels = tf.constant([[1.]] * batch_size)\n",
        "\n",
        "            discriminator.trainable = False\n",
        "\n",
        "            gan.train_on_batch(noise, generator_labels)\n",
        "\n",
        "        plot_multiple_images_tf(fake_images, 8)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADawDuEK3tfr"
      },
      "source": [
        "You can scroll through the output cell to see how the fake images improve per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1lhjSj0xGL8"
      },
      "outputs": [],
      "source": [
        "train_gan(gan, dataset, random_normal_dimensions, n_epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNaqSXTX5859"
      },
      "source": [
        "### Com uma GAN muito simples é notório que acabou se tornando \"enbiesada\" e suas saídas se parecem muito, com 3 cachorros que parecem se repetir continuamente, talvez pela simplicidade de suas características, ou por um barulho parecido"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}